{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Languages of Journals using OJS <a name=languages></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook objectives:\n",
    "1. Obtain <a href='https://github.com/google/cld3'>gcld3 language classifications</a> for the abstracts of articles published in a sample of 20,420 journals supported by OJS. \n",
    "2. Classify journals by their primary language of publishing.\n",
    "3. Classify journals based on whether they publish in multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://docs.google.com/document/d/103l90P0OuM0muOsmUYlnProG_Xo9yBR4IQ6INB21WaE/edit?usp=sharing'>This link</a> navigates to a Google doc with examples of journals using OJS to publish open access articles in **56 different languages**. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import ijson\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Google's Compact Language Detector v3 (gcld3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize <a href='https://github.com/google/cld3'>gcld3</a>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcld3\n",
    "classifier = gcld3.NNetLanguageIdentifier(min_num_bytes=0, max_num_bytes=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store a list of gcld3 language codes corresponding to the 56 languages known to be supported by OJS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_langs = ['af', 'ar', 'bg', 'bg-Latn', 'bs', 'ca', 'cs', 'da', 'de', 'el', 'el-Latn', 'en', 'es', 'et', 'eu',\n",
    "               'fa', 'fi', 'fr', 'gd', 'gl', 'hi', 'hi-Latn', 'hr', 'hu', 'hy', 'id', 'ig', 'is', 'it', 'ja',\n",
    "               'ja-Latn', 'ka', 'kk', 'ko', 'lt', 'mk', 'ms', 'ne', 'nl', 'no', 'pl', 'pt', 'ro', 'ru', 'ru-Latn',\n",
    "               'si', 'sk', 'sl', 'sr', 'sv', 'sw', 'ta', 'th', 'tr', 'uk', 'ur', 'uz', 'vi', 'zh', 'zh-Latn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that:\n",
    "<br>\n",
    "1. Opens and streams a 15 GB .json file of selected metadata [title, description, subject, language]  for the most recent 100 journal articles published in 20,420 OJS contexts;\n",
    "<br><br>\n",
    "2. Passes the 'description' values (article abstracts) to gcld3 to generate lists of predicted languages for each journal;\n",
    "<br><br>\n",
    "3. Returns a dict mapping journal issn to a list of gcld3-predicted language codes for article abstracts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json = os.path.join('data', 'beacon_metadata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstracts(path_to_json, classifier):\n",
    "    \n",
    "    issn_to_langs = defaultdict(list)\n",
    "    \n",
    "    issn = ''\n",
    "    description_prefix = ''\n",
    "    journal_count = 0\n",
    "    article_count = 0\n",
    "    \n",
    "    with open(path_to_json, 'r') as f: #open json file, streamed as dict(dict(list(str)))\n",
    "        for prefix, event, value in ijson.parse(f): #parse each json event iteratively\n",
    "            \n",
    "            if event == 'map_key': #if the event is a new dictionary\n",
    "                if re.search('\\d{4}-\\d{4}', value): #and the value of the key is an issn\n",
    "                    \n",
    "                    issn = value #store the issn to use as a prefix in ijson.parse()\n",
    "                    description_prefix = issn + '.' + 'description' + '.' + 'item' #store a prefix for filtering\n",
    "                    journal_count += 1 #add to the journal count\n",
    "                \n",
    "            elif (prefix, event) == (description_prefix, 'string'): #if the json event is a 'description' string\n",
    "            \n",
    "                if len(value) > 10: #if the 'description' string is not arbitrary\n",
    "                \n",
    "                    article_count += 1 #add to the article count\n",
    "                \n",
    "                    pred_ = classifier(text=value) #run gcld3\n",
    "                    if pred_.is_reliable: #if the language prediction is reliable\n",
    "                        issn_to_langs[issn].append(pred_.language) \n",
    "                        #pass the 'description' string to gcld3 and store the predicted language code\n",
    "                        #{journal issn: [list of predicted language codes for each article]}\n",
    "                        del pred_\n",
    "                        \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    print('Number of article abstracts: {}'.format(article_count))\n",
    "    print('Number of journals: {}'.format(len(issn_to_language)))\n",
    "    return issn_to_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "issn_to_langs = classify_descriptions(path_to_json, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(issn_to_langs))\n",
    "for k, v in issn_to_langs.items():\n",
    "    print(k) #issn for one journal\n",
    "    print(v) #list of gcld3 language classifications for most recent 100 or fewer articles published in journal\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that:\n",
    "<br>\n",
    "1. Filters the languages in issn_to_langs by inclusion in the list of `known_langs`;\n",
    "<br><br>\n",
    "2. Determines the most common language code in the list of abstract language classsifications for each journal;\n",
    "<br><br>\n",
    "3. Returns a dict mapping each issn to a single primary language code;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_journals(issn_to_langs, known_langs):\n",
    "    \n",
    "    for k, v in issn_to_langs.items():\n",
    "        issn_to_langs[k] = [lang for lang in v if lang in known_langs]\n",
    "    \n",
    "    issn_to_primary = {}\n",
    "    for k, v in issn_to_langs.items():\n",
    "        issn_to_lang[k] = Counter(v).most_common(1)[0][0]\n",
    "        \n",
    "    return issn_to_primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issn_to_primary = classify_journals(issn_to_langs, known_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a third function that counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts = defaultdict(int)\n",
    "for k, v in top_languages.items():\n",
    "    if v: #in case of empty lists\n",
    "        language_counts[v[0][0]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the language codes and their counts in a pd.Series\n",
    "language_distribution = pd.Series(list(issn_to_primary.values()))\n",
    "#Sort the language code Series by count\n",
    "language_distribution.sort_values(ascending=False, inplace=True)\n",
    "#Convert the Series to a DataFrame\n",
    "primaryLangs = pd.DataFrame(language_distribution, columns=['count'], index=language_distribution.index)\n",
    "primaryLangs.reset_index(inplace=True)\n",
    "primaryLangs.rename(columns = {'index':'language'}, inplace=True)\n",
    "#Total number of journals:\n",
    "total = primaryLangs['count'].sum()\n",
    "#Print n\n",
    "print('Total: {} journals'.format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar plot of the 10 most common languages in which OJS users publish their articles  (*n*=20,416) <br>\n",
    "Each bar represents the proportion of journals for which the specified language is their primary publishing language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "lang = sns.barplot(x=primaryLangs['count'][:10],\n",
    "                   y=['English', 'Bahasa Indonesia', 'Spanish', 'Portuguese', 'Ukrainian',\n",
    "                      'Russian', 'German', 'French', 'Polish', 'Arabic'],\n",
    "                   data=primaryLangs,\n",
    "                   orient='h',\n",
    "                   color='grey')\n",
    "\n",
    "ax.set(xlim=(0, 12000),\n",
    "       xlabel=\"Active journals using OJS\",\n",
    "       ylabel=\"Language\")\n",
    "\n",
    "\n",
    "matplotlib.pyplot.xticks([2000, 4000, 6000, 8000, 10000],\n",
    "                         ['2,000', '4,000', '6,000', '8,000', '10,000'])\n",
    "\n",
    "for p in lang.patches:\n",
    "    _x = p.get_x() + p.get_width()\n",
    "    _y = p.get_y() + p.get_height() - 0.2\n",
    "    percent = round(((p.get_width() / total) * 100), 1)\n",
    "    value = '{}'.format(str(percent)+'%')\n",
    "    lang.text(_x + 100, _y, value, ha='left', weight='bold')\n",
    "\n",
    "fig.savefig('OJS_top10_langs.png', bbox_inches=('tight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar plot of multilingualism among journals using OJS  (*n*=20,228) <br>\n",
    "Each bar represents the proportion of journals that published **5 or more articles in each of their publishing languages**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual = defaultdict(list)\n",
    "for k, v in issn_to_language.items():\n",
    "    for language in Counter(v).items():\n",
    "        if language[1] >= 5: #If the the number of article abstracts tagged as a given language ('en') exceeds 5\n",
    "            multilingual[k].append(language[0]) #Append the language (e.g.,'en') to a language list for the journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_counts = defaultdict(int)\n",
    "array_lengths = []\n",
    "\n",
    "for k, v in multilingual.items():\n",
    "    multiplier = len(v)\n",
    "    array_lengths.append(multiplier)\n",
    "    if multiplier >= 3:\n",
    "        multilingual_counts['Multi- (3+ languages)'] += 1\n",
    "    elif multiplier == 2:\n",
    "        multilingual_counts['Bi- (2 languages)'] += 1\n",
    "    elif multiplier == 1:\n",
    "        multilingual_counts['Mono- (1 language)'] += 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "total = 0\n",
    "for v in multilingual_counts.values():\n",
    "    total += v\n",
    "#Print n\n",
    "print('Total: {} journals'.format(total))\n",
    "\n",
    "#Print average length of language list per journal\n",
    "print('Average number of languages per journal: {}'.format( np.array(array_lengths).mean() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilingual_dist = pd.Series(multilingual_counts)\n",
    "\n",
    "multilingual_dist.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "multilingual_dist.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "\n",
    "mult = sns.barplot(y=multilingual_dist.index,\n",
    "                   x=multilingual_dist.values,\n",
    "                   orient='h',\n",
    "                   color='grey')\n",
    "\n",
    "ax.set(xlim=(0, 12000),\n",
    "       xlabel=\"Active journals using OJS\",\n",
    "       ylabel=\"*-lingual journals\")\n",
    "\n",
    "matplotlib.pyplot.xticks([2000, 4000, 6000, 8000, 10000],\n",
    "                         ['2,000', '4,000', '6,000', '8,000', '10,000'])\n",
    "\n",
    "for p in mult.patches:\n",
    "    _x = p.get_x() + p.get_width()\n",
    "    _y = p.get_y() + p.get_height() - 0.3\n",
    "    percent = round(((p.get_width() / total) * 100), 1)\n",
    "    value = '{}'.format(str(percent)+'%')\n",
    "    mult.text(_x + 250, _y, value, ha='left', weight='bold')\n",
    "\n",
    "fig.savefig('OJS_multilingual.png', bbox_inches=('tight'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
